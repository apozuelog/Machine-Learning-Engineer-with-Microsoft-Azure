# Optimizing an ML Pipeline in Azure

## Overview
**This project is part of the Udacity Azure ML Nanodegree. In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model. This model is then compared to an Azure AutoML run.**

## Summary
**Problem Statement: We will analyse the bank marketing dataset and train it to determine whether a customer will make a term deposit or not. We can determine the features which influence the outcome so that in our next marketing campaign we can identify the target customers who have a higher probability of converting and making a term deposit. The label "y" tells us whether a customer is subscribed to a term deposit or not and this is the target column for predictions.**



## Scikit-learn Pipeline
**Pipeline Architecture: We first created a compute instance to spin up a virtual machine and provision correct resources for that virtual machine. Once a compute instance is created we used it to launch a jupyter notebook which is used to access the existing workspace, create an experiment and a compute cluster(or find an existing one).**

**Data: We created a Tabular Dataset from a delimited file behind a public web url. Next we have used the clean data function to clean our data. Since machine learning models accept only numerical data we will convert months and weekdays into numbers, and one hot encode non numeric features.**

**Hyperparameters: The hyper parameters which are tuned in this model are C (which is inverse of regularization strength) and max-iter.**


**What are the benefits of the parameter sampler you chose?**

**We have used Random Parameter sampling as it supports both discrete and continuous parameters and also early termination of low performance runs. In Random Sampling hyper parameter values are chosen randomly from the defined limits.**

**What are the benefits of the early stopping policy you chose?**

**The early stopping policy chosen for this ML Pipeline Bandit Policy and the reason for choosing this is that the comparsion is based on best performing run hence runs which have a huge difference from the best performing training run are terminated. Slack factor or slack amount defines the allowable slack in primary metric.**

## AutoML
**The best performing model generated by AutoML was Voting Ensemble.**

![alt text](https://github.com/PurvajaDurga/Project1-Optimizing-an-ML-Pipeline-in-Azure/blob/main/images/automl.JPG)
![alt text](https://github.com/PurvajaDurga/Project1-Optimizing-an-ML-Pipeline-in-Azure/blob/main/images/model.JPG)

![alt text](https://github.com/PurvajaDurga/Project1-Optimizing-an-ML-Pipeline-in-Azure/blob/main/images/a1.JPG)
![alt text](https://github.com/PurvajaDurga/Project1-Optimizing-an-ML-Pipeline-in-Azure/blob/main/images/a2.JPG)
![alt text](https://github.com/PurvajaDurga/Project1-Optimizing-an-ML-Pipeline-in-Azure/blob/main/images/a3.JPG)
![alt text](https://github.com/PurvajaDurga/Project1-Optimizing-an-ML-Pipeline-in-Azure/blob/main/images/a4.JPG)

## Future work
**In future experiments for azure ml using Python SDK I would like to try out other scikit-learn models for classification and see if we can improve the accuracy. For autoML I will retrieve the top features from the model explanation and then reduce the number of features by using the top features. I would also like to experiment with number of cross validations(CV) and see if reducing the number affects the accuracy.This is because higher value of CV results in longer training time and thus increases cost. On the other hand very small values of CV will lead to over-fitting. I would also like to explore how to deal with class-imbalance issue.**


## Proof of cluster clean up
**Compute cluster was deleted.**
![alt text](https://github.com/PurvajaDurga/Project1-Optimizing-an-ML-Pipeline-in-Azure/blob/main/images/cluster%20deleted.JPG)

